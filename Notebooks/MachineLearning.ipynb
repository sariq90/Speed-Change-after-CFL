{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "from sklearn import preprocessing\n",
    "from sklearn import model_selection\n",
    "import os\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.metrics import f1_score,recall_score,precision_score\n",
    "import itertools as it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#list of manually picked true positives\n",
    "positives = [\n",
    "\t'AA16064612',\n",
    "\t'AA15898033',\n",
    "\t'AA16859504',\n",
    "\t'AA15555547',\n",
    "\t'AA16253838',\n",
    "\t'AA15690400',\n",
    "\t'AA16482851',\n",
    "\t'AA16650075',\n",
    "\t'AA17123584',\n",
    "\t'AA16916241',\n",
    "\t'AA17152178',\n",
    "\t'AA16589401',\n",
    "\t'AA17060787',\n",
    "\t'AA17130951',\n",
    "\t'AA15363462',\n",
    "\t'AA16857365',\n",
    "\t'AA16315097',\n",
    "\t'AA16658861',\n",
    "\t'AA15200234',\n",
    "\t'AA15653581',\n",
    "\t'AA16192547',\n",
    "\t'AA17026936',\n",
    "\t'AA15159907',\n",
    "\t'AA17054885',\n",
    "\t'AA15923342',\n",
    "\t'AA16073135',\n",
    "\t'AA16489819',\n",
    "\t'AA17051095',\n",
    "\t'AA15121656',\n",
    "\t'AA17205192',\n",
    "\t'AA17080146',\n",
    "\t'AA15964197',\n",
    "\t'AA16196411',\n",
    "\t'AA16576061',\n",
    "\t'AA16435085',\n",
    "\t'AA16176520',\n",
    "\t'AA16004931',\n",
    "\t'AA15793620',\n",
    "\t'AA15551849',\n",
    "\t'AA16879602',\n",
    "\t'AA15617742',\n",
    "\t'AA16524282',\n",
    "\t'AA16552065',\n",
    "\t'AA15310198',\n",
    "\t'AA15625977',\n",
    "\t'AA16907969',\n",
    "\t'AA16678130',\n",
    "\t'AA16095467',\n",
    "\t'AA16385441',\n",
    "\t'AA16171152',\n",
    "\t'AA16824984',\n",
    "\t'AA16921682',\n",
    "\t'AA16636556',\n",
    "\t'AA16744631',\n",
    "\t'AA16999415',\n",
    "\t'AA15499446',\n",
    "\t'AA16344473',\n",
    "\t'AA16961156',\n",
    "\t'AA16189242',\n",
    "\t'AA17158789',\n",
    "\t'AA15749776',\n",
    "\t'AA16895405',\n",
    "\t'AA15198624',\n",
    "\t'AA15853554',\n",
    "\t'AA15204685',\n",
    "\t'AA16274578',\n",
    "\t'AA15949178',\n",
    "\t'AA15886116',\n",
    "\t'AA15190364',\n",
    "\t'AA15433376',\n",
    "\t'AA17237470',\n",
    "\t'AA15433050',\n",
    "\t'AA16134022',\n",
    "\t'AA16620792',\n",
    "\t'AA16977468',\n",
    "\t'AA15515743',\n",
    "\t'AA17091147',\n",
    "\t'AA15618542',\n",
    "\t'AA15588480',\n",
    "\t'AA16584718',\n",
    "\t'AA16433513',\n",
    "\t'AA16505331',\n",
    "\t'AA15259877',\n",
    "\t'AA15313819',\n",
    "\t'AA16820543',\n",
    "\t'AA15775132',\n",
    "\t'AA16298995',\n",
    "\t'AA15929560',\n",
    "\t'AA16488663',\n",
    "\t'AA15694903',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full train set of suitable flights\n",
    "df_train = pd.read_pickle(\"../pickles/ifpsid_train.pickle\")\n",
    "\n",
    "# test set without heathrow data but including true positives from manual data (-1 is a true positive)\n",
    "df_test = pd.read_pickle(\"../pickles/df_test.pickle\")\n",
    "\n",
    "## full dataframes with constructed feature vectors for machine learning\n",
    "# l2-normalized histogram with 12 bins\n",
    "df_hist_l2_b12 = pd.read_pickle(\"../pickles/df_hist_l2_12bins.pickle\")\n",
    "\n",
    "# linear-interpolated fft with 16 frequency portions\n",
    "df_fft_lip = pd.read_pickle(\"../pickles/df_fft_lip.pickle\")\n",
    "\n",
    "## derived dataframes with constructed feature vectors merged to train and test data;\n",
    "## df_train and df_test are derived from df_ifpsid_suitable via train-test-split\n",
    "# train\n",
    "train_fft = pd.merge(df_train, df_fft_lip, how='inner', on=['ifpsid'])\n",
    "train_hist = pd.merge(df_train, df_hist_l2_b12, how='inner', on=['ifpsid'])\n",
    "# test\n",
    "test_fft = pd.merge(df_test, df_fft_lip, how='inner', on=['ifpsid'])\n",
    "test_hist = pd.merge(df_test, df_hist_l2_b12, how='inner', on=['ifpsid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## custom grid search for each method (for more control)\n",
    "def search_IF_FFT(params,freq_count,train_sample='full',verbose=False,random_state=1337,n_jobs=-1):\n",
    "    # hyperparam sets\n",
    "    grid = [dict(zip(params.keys(), combination)) for combination in it.product(*(params[key] for key in params.keys()))]\n",
    "    # acc lists\n",
    "    contamination_list,max_features_list,n_estimators_list,freq_list,sample_list,recall_list,precision_list,f1_list = ([] for i in range(8))\n",
    "    # train\n",
    "    if train_sample == 'full':\n",
    "        train = train_fft[['f{}'.format(i) for i in range(freq_count)]]\n",
    "    else:\n",
    "        train = train_fft[['f{}'.format(i) for i in range(freq_count)]].iloc[:train_sample]\n",
    "    # test\n",
    "    test = test_fft[['f{}'.format(i) for i in range(freq_count)]]\n",
    "    for n,gp in enumerate(grid):\n",
    "        if verbose:\n",
    "            print('{}/{}: {}'.format(n+1,len(grid),gp))\n",
    "        clf = IsolationForest(contamination=gp['contamination'],\n",
    "                              max_features=gp['max_features'],\n",
    "                              n_estimators=gp['n_estimators'],\n",
    "                              random_state=random_state,n_jobs=n_jobs)\n",
    "        # fit\n",
    "        clf.fit(train)\n",
    "        # predict\n",
    "        pred = clf.predict(test)\n",
    "        # construct result df cols\n",
    "        contamination_list.append(gp['contamination'])\n",
    "        max_features_list.append(gp['max_features'])\n",
    "        n_estimators_list.append(gp['n_estimators'])\n",
    "        freq_list.append(freq_count)\n",
    "        sample_list.append(train_sample)\n",
    "        recall_list.append(recall_score(y_true=df_test['true_positive'], y_pred=pred, pos_label=-1, average='binary'))\n",
    "        precision_list.append(precision_score(y_true=df_test['true_positive'], y_pred=pred, pos_label=-1, average='binary'))\n",
    "        f1_list.append(f1_score(y_true=df_test['true_positive'], y_pred=pred, pos_label=-1, average='binary'))\n",
    "    # construct result df\n",
    "    return pd.DataFrame(list(zip(contamination_list,max_features_list,n_estimators_list,freq_list,sample_list,recall_list,precision_list,f1_list)),\n",
    "                                  columns =['contamination','max_features','n_estimators','freq_count','sample_count','recall','precision','f1'])\n",
    "\n",
    "def search_IF_hist(params,train_sample='full',verbose=False,random_state=1337,n_jobs=-1):\n",
    "    # hyperparam sets\n",
    "    grid = [dict(zip(params.keys(), combination)) for combination in it.product(*(params[key] for key in params.keys()))]\n",
    "    # acc lists\n",
    "    contamination_list,max_features_list,n_estimators_list,sample_list,recall_list,precision_list,f1_list = ([] for i in range(7))\n",
    "    # train\n",
    "    if train_sample == 'full':\n",
    "        train = train_hist[['h{}'.format(i) for i in range(12)]]\n",
    "    else:\n",
    "        train = train_hist[['h{}'.format(i) for i in range(12)]].iloc[:train_sample]\n",
    "    # test\n",
    "    test = test_hist[['h{}'.format(i) for i in range(12)]]\n",
    "    for n,gp in enumerate(grid):\n",
    "        if verbose:\n",
    "            print('{}/{}: {}'.format(n+1,len(grid),gp))\n",
    "        clf = IsolationForest(contamination=gp['contamination'],\n",
    "                              max_features=gp['max_features'],\n",
    "                              n_estimators=gp['n_estimators'],\n",
    "                              random_state=random_state,n_jobs=n_jobs)\n",
    "        # fit\n",
    "        clf.fit(train)\n",
    "        # predict\n",
    "        pred = clf.predict(test)\n",
    "        # construct result df cols\n",
    "        contamination_list.append(gp['contamination'])\n",
    "        max_features_list.append(gp['max_features'])\n",
    "        n_estimators_list.append(gp['n_estimators'])\n",
    "        sample_list.append(train_sample)\n",
    "        recall_list.append(recall_score(y_true=df_test['true_positive'], y_pred=pred, pos_label=-1, average='binary'))\n",
    "        precision_list.append(precision_score(y_true=df_test['true_positive'], y_pred=pred, pos_label=-1, average='binary'))\n",
    "        f1_list.append(f1_score(y_true=df_test['true_positive'], y_pred=pred, pos_label=-1, average='binary'))\n",
    "    # construct result df\n",
    "    return pd.DataFrame(list(zip(contamination_list,max_features_list,n_estimators_list,sample_list,recall_list,precision_list,f1_list)),\n",
    "                                  columns =['contamination','max_features','n_estimators','sample_count','recall','precision','f1'])\n",
    "\n",
    "def search_LOF_FFT(params,freq_count,train_sample='full',verbose=False,n_jobs=-1):\n",
    "    # hyperparam sets\n",
    "    grid = [dict(zip(params.keys(), combination)) for combination in it.product(*(params[key] for key in params.keys()))]\n",
    "    # acc lists\n",
    "    n_neighbors_list,algorithm_list,leaf_size_list,metric_list,p_list,contamination_list,freq_list,sample_list,recall_list,precision_list,f1_list = ([] for i in range(11))\n",
    "    # train\n",
    "    if train_sample == 'full':\n",
    "        train = train_fft[['f{}'.format(i) for i in range(freq_count)]]\n",
    "    else:\n",
    "        train = train_fft[['f{}'.format(i) for i in range(freq_count)]].iloc[:train_sample]\n",
    "    # test\n",
    "    test = test_fft[['f{}'.format(i) for i in range(freq_count)]]\n",
    "    for n,gp in enumerate(grid):\n",
    "        if verbose:\n",
    "            print('{}/{}: {}'.format(n+1,len(grid),gp))\n",
    "        clf = LocalOutlierFactor(n_neighbors=gp['n_neighbors'],\n",
    "                              algorithm=gp['algorithm'],\n",
    "                              leaf_size=gp['leaf_size'],\n",
    "                              metric=gp['metric'],\n",
    "                              p=gp['p'],\n",
    "                              contamination=gp['contamination'],\n",
    "                              novelty=True,n_jobs=n_jobs)\n",
    "        # fit\n",
    "        clf.fit(train)\n",
    "        # predict\n",
    "        pred = clf.predict(test)\n",
    "        # construct result df cols\n",
    "        n_neighbors_list.append(gp['n_neighbors'])\n",
    "        algorithm_list.append(gp['algorithm'])\n",
    "        leaf_size_list.append(gp['leaf_size'])\n",
    "        metric_list.append(gp['metric'])\n",
    "        p_list.append(gp['p'])\n",
    "        contamination_list.append(gp['contamination'])\n",
    "        freq_list.append(freq_count)\n",
    "        sample_list.append(train_sample)\n",
    "        recall_list.append(recall_score(y_true=df_test['true_positive'], y_pred=pred, pos_label=-1, average='binary'))\n",
    "        precision_list.append(precision_score(y_true=df_test['true_positive'], y_pred=pred, pos_label=-1, average='binary'))\n",
    "        f1_list.append(f1_score(y_true=df_test['true_positive'], y_pred=pred, pos_label=-1, average='binary'))\n",
    "    # construct result df\n",
    "    return pd.DataFrame(list(zip(n_neighbors_list,algorithm_list,leaf_size_list,metric_list,p_list,contamination_list,freq_list,sample_list,recall_list,precision_list,f1_list)),\n",
    "                                  columns =['n_neighbors','algorithm','leaf_size','metric','p','contamination','freq_count','sample_count','recall','precision','f1'])\n",
    "\n",
    "def search_LOF_hist(params,train_sample='full',verbose=False,n_jobs=-1):\n",
    "    # hyperparam sets\n",
    "    grid = [dict(zip(params.keys(), combination)) for combination in it.product(*(params[key] for key in params.keys()))]\n",
    "    # acc lists\n",
    "    n_neighbors_list,algorithm_list,leaf_size_list,metric_list,p_list,contamination_list,sample_list,recall_list,precision_list,f1_list = ([] for i in range(10))\n",
    "    # train\n",
    "    if train_sample == 'full':\n",
    "        train = train_hist[['h{}'.format(i) for i in range(12)]]\n",
    "    else:\n",
    "        train = train_hist[['h{}'.format(i) for i in range(12)]].iloc[:train_sample]\n",
    "    # test\n",
    "    test = test_hist[['h{}'.format(i) for i in range(12)]]\n",
    "    for n,gp in enumerate(grid):\n",
    "        if verbose:\n",
    "            print('{}/{}: {}'.format(n+1,len(grid),gp))\n",
    "        clf = LocalOutlierFactor(n_neighbors=gp['n_neighbors'],\n",
    "                              algorithm=gp['algorithm'],\n",
    "                              leaf_size=gp['leaf_size'],\n",
    "                              metric=gp['metric'],\n",
    "                              p=gp['p'],\n",
    "                              contamination=gp['contamination'],\n",
    "                              novelty=True,n_jobs=n_jobs)\n",
    "        # fit\n",
    "        clf.fit(train)\n",
    "        # predict\n",
    "        pred = clf.predict(test)\n",
    "        # construct result df cols\n",
    "        n_neighbors_list.append(gp['n_neighbors'])\n",
    "        algorithm_list.append(gp['algorithm'])\n",
    "        leaf_size_list.append(gp['leaf_size'])\n",
    "        metric_list.append(gp['metric'])\n",
    "        p_list.append(gp['p'])\n",
    "        contamination_list.append(gp['contamination'])\n",
    "        sample_list.append(train_sample)\n",
    "        recall_list.append(recall_score(y_true=df_test['true_positive'], y_pred=pred, pos_label=-1, average='binary'))\n",
    "        precision_list.append(precision_score(y_true=df_test['true_positive'], y_pred=pred, pos_label=-1, average='binary'))\n",
    "        f1_list.append(f1_score(y_true=df_test['true_positive'], y_pred=pred, pos_label=-1, average='binary'))\n",
    "    # construct result df\n",
    "    return pd.DataFrame(list(zip(n_neighbors_list,algorithm_list,leaf_size_list,metric_list,p_list,contamination_list,sample_list,recall_list,precision_list,f1_list)),\n",
    "                                  columns =['n_neighbors','algorithm','leaf_size','metric','p','contamination','sample_count','recall','precision','f1'])\n",
    "\n",
    "def search_OCSVM_FFT(params,freq_count,train_sample='full',verbose=False):\n",
    "    # hyperparam sets\n",
    "    grid = [dict(zip(params.keys(), combination)) for combination in it.product(*(params[key] for key in params.keys()))]\n",
    "    # acc lists\n",
    "    kernel_list,degree_list,gamma_list,coef0_list,tol_list,nu_list,shrinking_list,freq_list,sample_list,recall_list,precision_list,f1_list = ([] for i in range(12))\n",
    "    # train\n",
    "    if train_sample == 'full':\n",
    "        train = train_fft[['f{}'.format(i) for i in range(freq_count)]]\n",
    "    else:\n",
    "        train = train_fft[['f{}'.format(i) for i in range(freq_count)]].iloc[:train_sample]\n",
    "    # test\n",
    "    test = test_fft[['f{}'.format(i) for i in range(freq_count)]]\n",
    "    for n,gp in enumerate(grid):\n",
    "        if verbose:\n",
    "            print('{}/{}: {}'.format(n+1,len(grid),gp))\n",
    "        clf = OneClassSVM(kernel=gp['kernel'],\n",
    "                              degree=gp['degree'],\n",
    "                              gamma=gp['gamma'],\n",
    "                              coef0=gp['coef0'],\n",
    "                              tol=gp['tol'],\n",
    "                              nu=gp['nu'],\n",
    "                              shrinking=gp['shrinking'])\n",
    "        # fit\n",
    "        clf.fit(train)\n",
    "        # predict\n",
    "        pred = clf.predict(test)\n",
    "        # construct result df cols\n",
    "        kernel_list.append(gp['kernel'])\n",
    "        degree_list.append(gp['degree'])\n",
    "        gamma_list.append(gp['gamma'])\n",
    "        coef0_list.append(gp['coef0'])\n",
    "        tol_list.append(gp['tol'])\n",
    "        nu_list.append(gp['nu'])\n",
    "        shrinking_list.append(gp['shrinking'])\n",
    "        freq_list.append(freq_count)\n",
    "        sample_list.append(train_sample)\n",
    "        recall_list.append(recall_score(y_true=df_test['true_positive'], y_pred=pred, pos_label=-1, average='binary'))\n",
    "        precision_list.append(precision_score(y_true=df_test['true_positive'], y_pred=pred, pos_label=-1, average='binary'))\n",
    "        f1_list.append(f1_score(y_true=df_test['true_positive'], y_pred=pred, pos_label=-1, average='binary'))\n",
    "    # construct result df\n",
    "    return pd.DataFrame(list(zip(kernel_list,degree_list,gamma_list,coef0_list,tol_list,nu_list,shrinking_list,freq_list,sample_list,recall_list,precision_list,f1_list)),\n",
    "                                  columns =['kernel','degree','gamma','coef0','tol','nu','shrinking','freq_count','sample_count','recall','precision','f1'])\n",
    "\n",
    "def search_OCSVM_hist(params,train_sample='full',verbose=False):\n",
    "    # hyperparam sets\n",
    "    grid = [dict(zip(params.keys(), combination)) for combination in it.product(*(params[key] for key in params.keys()))]\n",
    "    # acc lists\n",
    "    kernel_list,degree_list,gamma_list,coef0_list,tol_list,nu_list,shrinking_list,sample_list,recall_list,precision_list,f1_list = ([] for i in range(11))\n",
    "    # train\n",
    "    if train_sample == 'full':\n",
    "        train = train_hist[['h{}'.format(i) for i in range(12)]]\n",
    "    else:\n",
    "        train = train_hist[['h{}'.format(i) for i in range(12)]].iloc[:train_sample]\n",
    "    # test\n",
    "    test = test_hist[['h{}'.format(i) for i in range(12)]]\n",
    "    for n,gp in enumerate(grid):\n",
    "        if verbose:\n",
    "            print('{}/{}: {}'.format(n+1,len(grid),gp))\n",
    "        clf = OneClassSVM(kernel=gp['kernel'],\n",
    "                              degree=gp['degree'],\n",
    "                              gamma=gp['gamma'],\n",
    "                              coef0=gp['coef0'],\n",
    "                              tol=gp['tol'],\n",
    "                              nu=gp['nu'],\n",
    "                              shrinking=gp['shrinking'])\n",
    "        # fit\n",
    "        clf.fit(train)\n",
    "        # predict\n",
    "        pred = clf.predict(test)\n",
    "        # construct result df cols\n",
    "        kernel_list.append(gp['kernel'])\n",
    "        degree_list.append(gp['degree'])\n",
    "        gamma_list.append(gp['gamma'])\n",
    "        coef0_list.append(gp['coef0'])\n",
    "        tol_list.append(gp['tol'])\n",
    "        nu_list.append(gp['nu'])\n",
    "        shrinking_list.append(gp['shrinking'])\n",
    "        sample_list.append(train_sample)\n",
    "        recall_list.append(recall_score(y_true=df_test['true_positive'], y_pred=pred, pos_label=-1, average='binary'))\n",
    "        precision_list.append(precision_score(y_true=df_test['true_positive'], y_pred=pred, pos_label=-1, average='binary'))\n",
    "        f1_list.append(f1_score(y_true=df_test['true_positive'], y_pred=pred, pos_label=-1, average='binary'))\n",
    "    # construct result df\n",
    "    return pd.DataFrame(list(zip(kernel_list,degree_list,gamma_list,coef0_list,tol_list,nu_list,shrinking_list,sample_list,recall_list,precision_list,f1_list)),\n",
    "                                  columns =['kernel','degree','gamma','coef0','tol','nu','shrinking','sample_count','recall','precision','f1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### examples of testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "## testing if_fft\n",
    "params = {'contamination': [0.0053],\n",
    "        'max_features': [4],\n",
    "        'n_estimators': [100,200,300,400,500]}\n",
    "df_if_fft = search_IF_FFT(params=params,freq_count=4,train_sample=100,verbose=True)\n",
    "for f in [2,4,8]:\n",
    "    params['max_features'] = [f]\n",
    "    for s in [1000,10000,20000,40000,80000,'full']:\n",
    "        #print(\"Working on f={}, s={}\".format(f,s))\n",
    "        df_if_fft = pd.concat([df_if_fft,search_IF_FFT(params=params,freq_count=f,train_sample=s,verbose=True)],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_if_fft.query('recall >= 0.95').sort_values(by='precision',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "## testing if_hist\n",
    "params = {'contamination': ['auto',0.06,0.07,0.08,0.09,0.1],\n",
    "        'max_features': [12],\n",
    "        'n_estimators': [100,200,300,400,500]}\n",
    "df_if_hist = search_IF_hist(params=params,train_sample=100)\n",
    "for s in [1000,10000,20000,40000,80000,'full']:\n",
    "    #print(\"Working on {}\".format(s))\n",
    "    df_if_hist = pd.concat([df_if_hist,search_IF_hist(params=params,train_sample=s)],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_if_hist.query('recall >= 0.95').sort_values(by='precision',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "## testing lof_fft\n",
    "params = {'n_neighbors': [1000,1500],\n",
    "          'algorithm': ['auto'],\n",
    "          'leaf_size': [30],\n",
    "          'metric': ['minkowski'],\n",
    "          'p': [2,3,4],\n",
    "          'contamination': ['auto',0.07]}\n",
    "df_lof_fft = search_LOF_FFT(params=params,freq_count=1,train_sample=100)\n",
    "for f in [2,4,8]:\n",
    "    for s in [10000,20000,40000]:\n",
    "        #print(\"Working on f={}, s={}\".format(f,s))\n",
    "        df_lof_fft = pd.concat([df_lof_fft,search_LOF_FFT(params=params,freq_count=f,train_sample=s,verbose=True)],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lof_fft.query('recall >= 0.95').sort_values(by='precision',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "## testing lof_hist\n",
    "params = {'n_neighbors': [20,50,75],\n",
    "          'algorithm': ['auto'],\n",
    "          'leaf_size': [30],\n",
    "          'metric': ['minkowski'],\n",
    "          'p': [4,5,6,7,8],\n",
    "          'contamination': ['auto',0.07,0.08]}\n",
    "df_lof_hist = search_LOF_hist(params=params,train_sample=100)\n",
    "for s in [100]:\n",
    "    #print(\"Working on s={}\".format(s))\n",
    "    df_lof_hist = pd.concat([df_lof_hist,search_LOF_hist(params=params,train_sample=s,verbose=True)],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lof_hist.query('recall >= 0.87').sort_values(by='precision',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "## testing ocsvm_fft\n",
    "params = {'kernel': ['rbf','poly'],\n",
    "          'degree': [3],\n",
    "          'gamma': ['scale'],\n",
    "          'coef0': [0.0,0.5],\n",
    "          'tol': [1e-3],\n",
    "          'nu': [0.02,0.04,0.06,0.08,0.1,0.12,0.14,0.16,0.18,0.2,0.22,0.24,0.26,0.28,0.3,0.4,0.5,0.7,0.9],\n",
    "          'shrinking': [True]}\n",
    "df_ocsvm_fft = search_OCSVM_FFT(params=params,freq_count=1,train_sample=1000)\n",
    "for f in [2,4,8,12]:\n",
    "    for s in [5000,10000,20000,40000]:\n",
    "        #print(\"Working on f={}, s={}\".format(f,s))\n",
    "        df_ocsvm_fft = pd.concat([df_ocsvm_fft,search_OCSVM_FFT(params=params,freq_count=f,train_sample=s,verbose=True)],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ocsvm_fft.query('recall >= 0.95').sort_values(by='precision',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "## testing ocsvm_hist\n",
    "params = {'kernel': ['poly'],\n",
    "          'degree': [2,4,5,6,7],\n",
    "          'gamma': ['scale'],\n",
    "          'coef0': [0.0,0.5,1.0],\n",
    "          'tol': [1e-3],\n",
    "          'nu': [0.16,0.18,0.2,0.22],\n",
    "          'shrinking': [True]}\n",
    "\n",
    "df_ocsvm_hist = search_OCSVM_hist(params=params,train_sample=1000)\n",
    "for s in [20000]:\n",
    "    print(\"Working on s={}\".format(s))\n",
    "    df_ocsvm_hist = pd.concat([df_ocsvm_hist,search_OCSVM_hist(params=params,train_sample=s,verbose=True)],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ocsvm_hist.query('recall >= 0.95').sort_values(by='precision',ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
